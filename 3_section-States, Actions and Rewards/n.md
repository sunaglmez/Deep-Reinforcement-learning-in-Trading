# ğŸ“˜ Elements of Reinforcement Learning

Bu derste, pekiÅŸtirmeli Ã¶ÄŸrenmenin temel Ã¶ÄŸeleri olan **state (durum)**, **action (eylem)** ve **reward (Ã¶dÃ¼l)** kavramlarÄ± aÃ§Ä±klanmaktadÄ±r.

## ğŸ® Ã–rnek: Pong Oyunu

- Oyuncu Ã¼Ã§ eylemden birini seÃ§er: `up`, `down`, `stay`
- Bu seÃ§imler **action** olarak adlandÄ±rÄ±lÄ±r ve her zaman adÄ±mÄ±nda yapÄ±lÄ±r (`t`)

## Finansal Ä°ÅŸlemlerde Action

YatÄ±rÄ±mcÄ± genelde ÅŸu Ã¼Ã§ karardan birini verir:
- `buy` (al)
- `hold` (bekle)
- `sell` (sat)

Bu kararlar da **action** olarak deÄŸerlendirilir.

## State (Durum) Nedir?

### Pongâ€™ta:
- Topun ve raketin konumu: `state`

### Piyasada:
- OHLC verileri (Open, High, Low, Close)
- GÃ¶stergeler (RSI, MA, momentum, volatilite)
- FarklÄ± zaman Ã¶lÃ§eklerinde veriler

> TÃ¼m bu bilgiler, zaman anÄ±ndaki bir durumu temsil eden `state vector (Sâ‚œ)`'yi oluÅŸturur.

## ğŸ“Š Ã–rnek: Tesla - 29 Haziran 2020

- OHLC verisi yeterli deÄŸildir.
- KapanÄ±ÅŸ fiyatÄ±ndaki deÄŸiÅŸim, RSI gibi gÃ¶stergeler kullanÄ±lÄ±r.
- Daha doÄŸru kararlar iÃ§in daha zengin bir state gerekir.

## ğŸ§  Ä°nsan YatÄ±rÄ±mcÄ± BenzerliÄŸi

- Ä°nsan da piyasayÄ± gÃ¶zlemler ve karar verir.
- RL sistemleri de benzer ÅŸekilde durumu analiz eder ve eylem seÃ§er.

## ğŸ¤” Peki 30 Haziranâ€™da Ne YapmalÄ±?

- Sistem, `Sâ‚œ` durumuna gÃ¶re `action` seÃ§ecek.
- Karar, bu eylemden alÄ±nacak **reward (Ã¶dÃ¼l)** ile ilgilidir.

## ğŸ¯ Reward (Ã–dÃ¼l) NasÄ±l Belirlenir?

- "Buy" yaptÄ±ysa ve fiyat arttÄ±ysa â†’ pozitif Ã¶dÃ¼l
- Fiyat dÃ¼ÅŸtÃ¼yse â†’ negatif Ã¶dÃ¼l

> Peki Ã¶dÃ¼l neye gÃ¶re tanÄ±mlanmalÄ±?

## â­ Sonraki AdÄ±m

> ğŸ“Œ Bir sonraki derste: **Reward Function Design** (Ã–dÃ¼l Fonksiyonu TasarÄ±mÄ±)

## ğŸ§© Ã–zet Tablosu

| BileÅŸen | AÃ§Ä±klama |
|--------|----------|
| `State` | Piyasadan algÄ±lanan veri (fiyatlar, gÃ¶stergeler vs.) |
| `Action` | AlÄ±nan karar (buy, hold, sell) |
| `Reward` | Eylem sonucunda elde edilen kazanÃ§/kayÄ±p |
